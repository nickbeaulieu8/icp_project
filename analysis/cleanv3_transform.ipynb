{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(\"../data/cps_clean_v3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped columns: ['ELDCH', 'YNGCH', 'YRIMMIG', 'CLASSWKR', 'UHRSWORKT', 'WKSTAT', 'CLASSWLY', 'FULLPART', 'WKXPNS', 'NWLOOKWK', 'WANTJOB']\n"
     ]
    }
   ],
   "source": [
    "# Calculate the count of missing values for each column\n",
    "missing_counts = df.isna().sum()\n",
    "\n",
    "# Identify columns with more than 100000 missing values\n",
    "cols_to_drop = missing_counts[missing_counts > 100000].index\n",
    "\n",
    "# Drop the identified columns from the DataFrame\n",
    "df = df.drop(columns=cols_to_drop)\n",
    "\n",
    "# (Optional) Print the names of dropped columns\n",
    "print(\"Dropped columns:\", list(cols_to_drop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the allowed features\n",
    "oh_columns = ['RELATE', 'SEX', 'MARST', 'VETSTAT', 'FTYPE', 'FAMKIND', 'FAMREL', 'CITIZEN', \n",
    "                    'NATIVITY', 'HISPAN', 'EMPSTAT', 'LABFORCE',  'SCHLCOLL', 'DIFFHEAR', 'DIFFEYE', \n",
    "                    'DIFFREM', 'DIFFPHYS', 'DIFFMOB', 'DIFFCARE', 'DIFFANY', 'WORKLY', 'PENSION', \n",
    "                    'MIGRATE1', 'DISABWRK', 'QUITSICK']\n",
    "sbert_columns = ['OCC', 'IND', 'OCCLY', 'INDLY', 'BPL', 'RACE']\n",
    "inc_columns = ['FTOTVAL', 'INCTOT', 'INCWAGE', 'INCBUS', 'INCFARM', 'INCSS', 'INCWELFR', 'INCSSI', \n",
    "               'INCINT', 'INCUNEMP', 'INCWKCOM', 'INCVET', 'INCSURV', 'INCDISAB', 'INCDIVID', \n",
    "               'INCRENT', 'INCEDUC', 'INCCHILD', 'INCASIST', 'INCOTHER', 'ADJGINC', 'TAXINC']\n",
    "exluded_columns = ['YEAR', 'INCLOG', 'INCZERO_ONE', 'INCZERO_TWO', 'INCPER_DELTA', 'comp_zero', \n",
    "                   'comp_central', 'comp_promo', 'comp_demo']\n",
    "target_columns = ['INCLOG_DELTA']\n",
    "ss_columns = ['AGE', 'FAMSIZE', 'NCHILD', 'NCHLT5', 'NSIBS', 'EDUC', 'WKSWORK1',\n",
    "                'UHRSWORKLY', 'FIRMSIZE', 'NUMEMPS', 'MTHWELFR', 'HEALTH', 'INCPER']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select and copy the oh_columns from the original DataFrame into a new DataFrame\n",
    "new_df = df[oh_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in inc_columns:\n",
    "    # Clamp the values to a minimum of 1 to avoid issues with log10(0) or negative values\n",
    "    clamped_series = df[col].clip(lower=100)\n",
    "    # Apply the log10 transformation and divide by 6\n",
    "    transformed_series = np.log10(clamped_series) / 6\n",
    "    # Add the transformed column to new_df (using the same column name)\n",
    "    new_df[col] = transformed_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler on the selected columns and transform the data\n",
    "scaled_values = scaler.fit_transform(df[ss_columns])\n",
    "\n",
    "# Create a DataFrame with the scaled values, ensuring the index aligns with new_df\n",
    "scaled_df = pd.DataFrame(scaled_values, columns=ss_columns, index=df.index)\n",
    "\n",
    "# Concatenate the scaled columns to new_df\n",
    "new_df = pd.concat([new_df, scaled_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OCC\n",
    "# Read the occ_key file\n",
    "occ_df = pd.read_csv(\"../data/occ_key.csv\")\n",
    "occ_df.set_index(\"OCC_CODES\", inplace=True)\n",
    "\n",
    "# Keep only the occ_pca_i columns from occ_df\n",
    "occ_df = occ_df.filter(regex=\"^occ_pca_\")\n",
    "\n",
    "# Temporarily add the OCC column from df to new_df for merging purposes\n",
    "new_df[\"OCC_temp\"] = df[\"OCC\"]\n",
    "\n",
    "# Merge the occ_pca_i columns using OCC_temp as the key (matching occ_df's index) and then drop the temporary column\n",
    "new_df = new_df.merge(occ_df, left_on=\"OCC_temp\", right_index=True, how=\"left\")\n",
    "new_df.drop(columns=[\"OCC_temp\"], inplace=True)\n",
    "\n",
    "# OCCLY\n",
    "# Read the occ_key file\n",
    "occly_df = pd.read_csv(\"../data/occ_key.csv\")\n",
    "occly_df.set_index(\"OCC_CODES\", inplace=True)\n",
    "\n",
    "# Keep only the occ_pca_* columns and rename their prefix to occly_pca_\n",
    "occly_df = occly_df.filter(regex=\"^occ_pca_\")\n",
    "occly_df.rename(columns=lambda col: col.replace(\"occ_pca_\", \"occly_pca_\"), inplace=True)\n",
    "\n",
    "# Temporarily add the OCCLY column from df to new_df for merging purposes\n",
    "new_df[\"OCCLY_temp\"] = df[\"OCCLY\"]\n",
    "\n",
    "# Merge the occly_pca_i columns using OCCLY_temp as the key (matching occly_df's index)\n",
    "new_df = new_df.merge(occly_df, left_on=\"OCCLY_temp\", right_index=True, how=\"left\")\n",
    "\n",
    "# Drop the temporary key column\n",
    "new_df.drop(columns=[\"OCCLY_temp\"], inplace=True)\n",
    "\n",
    "# IND\n",
    "# Process IND: load the key file, filter, merge using df[\"IND\"]\n",
    "ind_df = pd.read_csv(\"../data/ind_key.csv\")\n",
    "ind_df.set_index(\"IND_CODES\", inplace=True)\n",
    "# Keep only the already labeled ind_pca_* columns\n",
    "ind_df = ind_df.filter(regex=\"^ind_pca_\")\n",
    "# Use a temporary key column for merging\n",
    "new_df[\"IND_temp\"] = df[\"IND\"]\n",
    "new_df = new_df.merge(ind_df, left_on=\"IND_temp\", right_index=True, how=\"left\")\n",
    "new_df.drop(columns=[\"IND_temp\"], inplace=True)\n",
    "\n",
    "# INDLY\n",
    "# Process INDLY: load the key file, filter and rename columns, merge using df[\"INDLY\"]\n",
    "indly_df = pd.read_csv(\"../data/ind_key.csv\")\n",
    "indly_df.set_index(\"IND_CODES\", inplace=True)\n",
    "indly_df = indly_df.filter(regex=\"^ind_pca_\")\n",
    "# Rename columns to change prefix from ind_pca_ to indly_pca_\n",
    "indly_df.rename(columns=lambda col: col.replace(\"ind_pca_\", \"indly_pca_\"), inplace=True)\n",
    "# Use a temporary key column for merging\n",
    "new_df[\"INDLY_temp\"] = df[\"INDLY\"]\n",
    "new_df = new_df.merge(indly_df, left_on=\"INDLY_temp\", right_index=True, how=\"left\")\n",
    "new_df.drop(columns=[\"INDLY_temp\"], inplace=True)\n",
    "\n",
    "# BPL\n",
    "# Process BPL: load key file, filter only columns starting with \"bpl_pca_\"\n",
    "bpl_df = pd.read_csv(\"../data/bpl_key.csv\")\n",
    "bpl_df.set_index(\"BPL_CODES\", inplace=True)\n",
    "bpl_df = bpl_df.filter(regex=\"^bpl_pca_\")\n",
    "\n",
    "# Temporarily add the BPL column from df for merging purposes\n",
    "new_df[\"BPL_temp\"] = df[\"BPL\"]\n",
    "\n",
    "# Merge the filtered BPL columns into new_df using the temporary key\n",
    "new_df = new_df.merge(bpl_df, left_on=\"BPL_temp\", right_index=True, how=\"left\")\n",
    "new_df.drop(columns=[\"BPL_temp\"], inplace=True)\n",
    "\n",
    "# RACE\n",
    "# Process RACE: load key file, filter only columns starting with \"race_pca_\"\n",
    "race_df = pd.read_csv(\"../data/race_key.csv\")\n",
    "race_df.set_index(\"RACE_CODES\", inplace=True)\n",
    "race_df = race_df.filter(regex=\"^race_pca_\")\n",
    "\n",
    "# Temporarily add the RACE column from df for merging purposes\n",
    "new_df[\"RACE_temp\"] = df[\"RACE\"]\n",
    "\n",
    "# Merge the filtered RACE columns into new_df using the temporary key\n",
    "new_df = new_df.merge(race_df, left_on=\"RACE_temp\", right_index=True, how=\"left\")\n",
    "new_df.drop(columns=[\"RACE_temp\"], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[\"INCLOG_DELTA\"] = df[\"INCLOG_DELTA\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df[exluded_columns] = df[exluded_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df.to_csv(\"../data/cleanv3_transform.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard scale the \"INCPER\" column from df\n",
    "scaler = StandardScaler()\n",
    "scaled_incpers = scaler.fit_transform(df[['INCPER']])\n",
    "\n",
    "# Add the scaled INCPER column to new_df\n",
    "new_df['INCPER'] = scaled_incpers\n",
    "\n",
    "# Save the updated new_df to the CSV file\n",
    "new_df.to_csv(\"../data/cleanv3_transform.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_features_to_add = [\n",
    "    [('INCTOT', 'spline', 20)]\n",
    "]\n",
    "new_features_to_add = [\n",
    "    [('EDUC', 'spline', 5)]\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
